\clearpage
\bigsection{Discussion}
\label{sec:discussion}

\subsection{Instrumentation before and after Structurizing the CFG}
\label{sub:discussion_structurize}
The \texttt{StructurizeCFG} pass in the LLVM compiler pipeline is a turning point. Before, we look at everything from the perspective of a single thread (or lane).
After this pass, the control-flow graph contains the per SIMD unit view, where an if-else was before, both branches can now be executed after each other.
It is important to note that the per unit perspective only applies to the CFG after this pass. All instructions apart from branch instructions stay the same and exhibit the per lane view.

For profile-guided optimizations, we have to decide if we want to instrument the CFG before or after structurization. In the case of basic block counters, this will lead to different results.
Before structurization, it is impossible to run through both branches of an if-else construct. After structurization, it is still impossible \emph{per lane}, but it is possible in the \emph{per unit} perspective.
If we count executions per lane, instrumenting before or after structurization does not make a semantic difference.
After \texttt{StructurizeCFG}, more counters are needed, because there are more basic blocks and LLVM does not know anymore that only one block of an if-else construct will be entered.
On the other hand if we count executions per unit, it does make a difference. More importantly, counting executions per unit before the CFG gets structurized leads to wrong results as LLVM expects than an else-block will not be entered if the if-block is executed. And this assumption is false for the per unit point of view.

Summarizing, there are two different possibilities for instrumentation. First, counting per lane, where we should instrument before structurization because it leads to less counters and makes no difference otherwise.
And second, counting per SIMD unit after structurization. These two opportunities represent the per lane and per unit view on a GPU.
The decision for the instrumentation is the same as for actually using collected data. If we collect counters before the \texttt{StructurizeCFG} pass, we need to annotate the results at the same point in the pipeline.
LLVM will propagate them when transforming the CFG in the structurization.
If we collect counters after structurization, we also need to annotate them afterwards. This means, the collected data is only available to the compiler after the \texttt{StructurizeCFG} pass.
Looking at CPUs, LLVM applies instrumentation and usage of counters at the end of the pipeline, after most optimizations.
This makes sense because the counters are used for linearization and getting data about an unoptimized CFG is not useful if the final CFG that needs to be linearized looks completely different.

The advantage of a per lane instrumentation is simplicity. The \texttt{PassManagerBuilder} can insert the needed passes easily (it runs before structurization) and we do not need to adjust any instrumentation code because the LLVM IR exhibits the per lane view.

To use per unit instrumentation, we need to add passes manually after structurization and cannot use the \texttt{PassManagerBuilder}.
Additionally, we need to change the PGO instrumentation pass that the increment instruction is only run on one lane and not on all lanes.
An advantage of the per unit view is that it is more similar to the code that gets executed on the hardware in the end.
If we compare two basic blocks, one always gets run by the whole unit, for the other only a single lane is active, e.g. to aggregate a result over the whole unit.
When we use per lane counting, the first basic block will be weighted a lot more important than the second one.
Per unit counting provides a more accurate view, both blocks are executed the same amount of times, so they are equally important. The amount of active lanes does not matter.

\subsection{Related Work}
\label{sub:relatedwork}
A part of this work is to profile shaders. There are many GPU profiling tools~\cite{UnityGPUProfiler, UnrealGPUProfiling, MSGPUUsage, PGI2014}.
Most of them show the needed computation time down to single draw calls or overall GPU performance statistics like occupancy\footnote{The amount of simultaneously executed threads on a \gls{cu}, hiding memory latency},used memory bandwidth and compute power~\cite{NvidiaNsight, NvidiaShaderPerf, AMDShaderAnalyzer}.
There are only few, which show detailed information about the inside of shaders. E.g GPUOcelot can trace single instructions in shaders when emulating CUDA applications on the GPU~\cite{GPUOcelot, Lakshminarayana2010}. Pyramid is an emulator and shader analyzer for various architectures, including AMD GCN~\cite{Pyramid}.
While emulation can provide accurate information, we cannot run our application at the same speed as on the GPU as the CPU has much less computational power.
Arm has something~\cite{Barton2013}.
In the high-performance computing space, they used Lynx~\cite{lynx} to instrument CUDA applications and automatically measure performance statistics~\cite{Farooqui2014}.

Benchmarks: Cuda SDK, Parboil, Rodinia, SHOC, Tensor (cite) but not Vulkan so we cannot use it. VComputeBench claims to be a general, publicly available benchmark for GPGPU~\cite{Mammeri2018}. However, we were unable to find these benchmarks online and the author did not respond to our questions.

\subsection{Future Work}
\label{sub:futurework}

\subsection{Conclusion}
\label{sub:conclusion}