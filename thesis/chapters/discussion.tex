\clearpage
\bigsection{Discussion}
\label{sec:discussion}

\subsection{Instrumentation before and after Structurizing the CFG}
\label{sub:discussion_structurize}
The \texttt{StructurizeCFG} pass in the LLVM compiler pipeline is a turning point. Before, we look at everything from the perspective of a single thread (or lane).
After this pass, the control-flow graph contains the per SIMD unit view, where an if-else was before, both branches can now be executed after each other.
It is important to note that the per unit perspective only applies to the CFG after this pass. All instructions apart from branch instructions stay the same and exhibit the per lane view.

For profile-guided optimizations, we have to decide if we want to instrument the CFG before or after structurization. In the case of basic block counters, this will lead to different results.
Before structurization, it is impossible to run through both branches of an if-else construct. After structurization, it is still impossible \emph{per lane}, but it is possible in the \emph{per unit} perspective.
If we count executions per lane, instrumenting before or after structurization does not make a semantic difference.
After \texttt{StructurizeCFG}, more counters are needed, because there are more basic blocks and LLVM does not know anymore that only one block of an if-else construct will be entered.
On the other hand if we count executions per unit, it does make a difference. More importantly, counting executions per unit before the CFG gets structurized leads to wrong results as LLVM expects than an else-block will not be entered if the if-block is executed. And this assumption is false for the per unit point of view.

Summarizing, there are two different possibilities for instrumentation. First, counting per lane, where we should instrument before structurization because it leads to fewer counters and makes no difference otherwise.
And second, counting per SIMD unit after structurization.
These two opportunities represent the per lane and per unit view on a GPU.
The decision for the instrumentation is the same as for actually using collected data. If we collect counters before the \texttt{StructurizeCFG} pass, we need to annotate the results at the same point in the pipeline.
LLVM will propagate them when transforming the CFG in the structurization.
If we collect counters after structurization, we also need to annotate them afterwards. This means, the collected data is only available to the compiler after the \texttt{StructurizeCFG} pass.
Looking at CPUs, LLVM applies instrumentation and usage of counters at the end of the pipeline, after most optimizations.
This makes sense because the counters are used for linearization and getting data about an unoptimized CFG is not useful if the final CFG that needs to be linearized looks completely different.

The advantage of a per lane instrumentation is simplicity. The \texttt{PassManagerBuilder} can insert the needed passes easily (it runs before structurization) and we do not need to adjust any instrumentation code because the LLVM IR exhibits the per lane view.

To use per unit instrumentation, we need to add passes manually after structurization and cannot use the \texttt{PassManagerBuilder}.
Additionally, we need to change the PGO instrumentation pass that the increment instruction is only run on one lane and not on all lanes.
An advantage of the per unit view is that it is more similar to the code that gets executed on the hardware in the end.
If we compare two basic blocks, one always gets run by the whole unit, for the other only a single lane is active, e.g. to aggregate a result over the whole unit.
When we use per lane counting, the first basic block will be weighted a lot more important than the second one.
Per unit counting provides a more accurate view, both blocks are executed the same amount of times, so they are equally important. The amount of active lanes does not matter.

\subsection{Related Work}
\label{sub:relatedwork}
A part of this work is to profile shaders. There are many GPU profiling tools~\cite{UnityGPUProfiler, UnrealGPUProfiling, MSGPUUsage, PGI2014}.
Most of them show the needed computation time down to single draw calls or overall GPU performance statistics like occupancy\footnote{The amount of simultaneously executed threads on a \gls{cu}, hiding memory latency},used memory bandwidth and compute power~\cite{NvidiaNsight, NvidiaShaderPerf, AMDShaderAnalyzer}.
There are only few, which show detailed information about the inside of shaders. E.g GPUOcelot can trace single instructions in shaders when emulating CUDA applications on the GPU~\cite{GPUOcelot, Lakshminarayana2010}. Pyramid is an emulator and shader analyzer for various architectures, including AMD GCN~\cite{Pyramid}.
While emulation can provide accurate information, we cannot run our application at the same speed as on the GPU as the CPU has much less computational power.
Arm has something~\cite{Barton2013}.
In the high-performance computing space, they used Lynx~\cite{Lynx} to instrument CUDA applications and automatically measure performance statistics~\cite{Farooqui2014}.

Benchmarks: Cuda SDK, Parboil, Rodinia, SHOC, Tensor but not Vulkan so we cannot use it. VComputeBench claims to be a general, publicly available benchmark for GPGPU~\cite{Mammeri2018}. However, we were unable to find these benchmarks online and the author did not respond to our questions.

\subsection{Future Work}
\label{sub:futurework}
This work does provide a good step into PGO on GPUs but of course it is not complete.
This section will explain possible directions for future work in this field.

When analyzing uniformity, we rely on the divergence analysis to give us information about uniform or divergent variables.
As mentioned before, this analysis does not yield perfectly accurate results at all steps in the compilation pipeline.
An opportunity for future work is to look into these problems, fix them where possible and find the best point to run this analysis.

The uniformity analysis does only analyze conditions and values from memory at the moment.
It would be interesting to expand this to image and buffer loads.
They make up a considerable part of the memory accesses in a shader, but analyzing them is more difficult and did not fit into the time frame of this thesis.

In addition to analyzing if a variable is uniform or not, we can also create statistics about how often a variable is uniform.
If the divergent cases only make up a low fraction of the executions, it can still be beneficial to optimize for the common case.
At the moment, we do not know how often this is the case.

Based on the basic block counters, we removed basic blocks which never get executed.
This worked good for two games but did not work for others.
As removing basic blocks was meant as a simple and dirty test, this is not too surprising.
However, it would be nice to have this test working for more games and collect more information about the effects.

A related bug in LLVM are the artifacts which show up in Ashes when using PGO.
We found one bug caused by PGO on GPUs in the \texttt{ControlHeightReduction} pass, we did not find the cause for this bug though.
Before PGO can be used in production environments, this bug should be fixed and more games should be tested with these optimizations.

Now, that we have methods to collect runtime data from shaders, this data can be used in the compiler to improve the optimization of shaders.
This includes many of the optimizations which we suggested in \cref{sub:optimizations}.
Hoisting loads out of conditional blocks for example is a promising candidate for rewarding optimizations.

The existing optimizations were applied to five different games.
The collected performance data give an impression of what we can expect of PGO on graphics cards.
There exist many more games with different engines and they all use the GPU in a slightly different way.
Thus, it would be interesting to compare the performance of PGO of more games and other Vulkan applications.

\subsection{Conclusion}
\label{sub:conclusion}
To our knowledge, this is the first work which leverages profile-guided optimizations on GPUs.
We started an introduction into the topic of PGO and GPUs and continued with our design and implementation to enable profile-guided optimizations on graphics cards.
Benchmarks of five different games and statistics about collected metrics give insights into potential performance gains and conclude the topic.

For PGO, we used the basic block counting functionality of LLVM and adjusted the driver and LLVM to get working counters on GPUs.
These counters give us information about unused basic blocks.
We create statistics about the amount of unused blocks use this information to remove the unused basic blocks.
In the game Dota 2, nearly \SI{20}{\percent} of the shader code are removed, in Warhammer even \SI{37}{\percent} and in the other games a let less.
This leads to three different configurations for running games.
We can run them without any changes in the compiler pipeline, we can enable the standard PGO options of LLVM by activating basic block counters, and we can additionally remove code which is never executed.

In these three modes, we analyzed the performance of five different games and a small test program.
The performance of the games mostly stayed the same, for some games it got a little faster when switching on PGO, for some it got slower.
Removing unused blocks has no measurable effect on the performance of the tested games.
Our small test application benefited most from removing unused code.
Removing \SI{92}{\percent} of the basic blocks led to a speed improvement of \SI{21.06 \pm 0.10}{\percent}.

An important property of shaders is the amount of registers they use.
The register count limits the amount of shaders which can run in parallel on one SIMD unit and thus it is important for the overall performance.
We looked at the used register usage of games in the same three configurations and found that it is mostly unchanged, even if a large fraction of blocks was removed for some games.
Mad Max contains a single shader where removing unused code eliminates a large amount of code, leading to a lot lower register usage.

In addition to counting basic blocks, this work contributes an instrumentation for LLVM which measures the uniformity of single variables.
We use this instrumentation to test conditions.
This tells us if branches are taken uniformly or not.
Averaging over all shaders and conditions, we find that for most games, the biggest category are static uniform branches.
This means the compiler can proof that these branches are always taken uniformly.
The other branches are either always uniform at runtime or divergent.
The fractions of these two categories varies between the games, there is no clear majority.

Apart from conditions, we reuse this instrumentation to analyze the values of memory loads.a
The fractions of the three categories for static uniform, dynamic uniform and divergent values vary a lot between games.
Divergent loads form the smallest category with under \SI{35}{\percent} for every game.
For Ashes and Warhammer, dynamic uniform loads are the common case.
For the rest of the games, static uniform loads make up more than half of the loads.

When writing passes in LLVM, we have to decide where in the compilation pipeline this pass should be inserted.
In the case of counting basic blocks, we have two main possibilities.
The default position when activating PGO is after most optimizations but before the CFG gets structurized.
An alternative position is after structurization.
As the CFG after structurization is closer to the actual control flow on the hardware, we come to the conclusion that the basic block counting instrumentation is better suited after structurization and that the counters should be incremented once per SIMD unit instead of counting all active lanes.
